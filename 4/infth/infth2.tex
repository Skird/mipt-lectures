\documentclass{article}
\input{common}

\begin{document}

\section{Энтропия Шеннона}

Пусть $\xi$~--- дискретная случайная величина, принимающая свои значения
с~вероятностями $(p_1, \ldots, p_m)$, тогда энтропия по Шеннону есть $H(\xi) =
\sum p_i \log_2 \frac{1}{p_i}$. Если величина задана на $(\mathbb{R},
\mathcal{B}(\mathbb{R}), P)$ и~умеет плотность $f_\xi$, то $H(\xi) = -E \log_2
f_\xi$.

Ясно, что $H(\xi) \ge 0$. Покажем, что $H(\xi) \le \log m, H(\xi) = \log m
\Leftrightarrow p_i = \frac{1}{m}$. Это очевидно следует из следующей леммы:

\begin{lemma}[неравенство Гиббса]
	Если $\sum q_i \le 1, q_i > 0$, то
	$$-\sum p_i \log p_i \le -\sum p_i \log q_i,$$
\end{lemma}
\begin{proof}
	По неравенству Йенсена $\sum p_i \log \frac{q_i}{p_i} \le \log \sum p_i
	\frac{q_i}{p_i} \le 0$.
\end{proof}

\section{Посимвольное кодирование}

Пусть $\Sigma$~--- алфавит, $T \in \Sigma^\ast$, $f: \Sigma \rightarrow \{0,
1\}^\ast$~--- некоторое кодирование символов, а~$f^{(n)}: \Sigma^n \rightarrow
\{0,1\}^\ast$~--- посимвольное сжатие текста.

\begin{definition}
	$f$~--- префиксное кодирование, если $\forall a, b \in \Sigma$ неверно, что
	$f(a) \sqsubset f(b)$ или $f(b) \sqsubset f(a)$.
\end{definition}

\begin{definition}
	Код $f$ называется неоднозначным, если $\exists x \ne y \in \Sigma^\ast: f(x)
	= f(y)$.
\end{definition}

Оптимальность будем рассматривать в~следующем смысле: пусть даны частоты $p_1,
\ldots, p_m$, с~которыми встречаются символы, тогда средней длиной кода $f$
называется $c(f) = \sum\limits_{i=1}^m p_i |f(a_i)|$.

\begin{lemma}[Крафта-Макмилана]
	Пусть $n_i = |f(a_i)|$. Пусть заданы частоты $n_1, \ldots, n_m$, тогда
	однозначный код с~такими длинами существует тогда и~только тогда, когда $\sum
	2^{-n_i} \le 1$.
\end{lemma}

\begin{theorem}
	Пусть $f$~--- однозначный код, тогда
	\begin{itemize}
		\item $f$~--- однозначный код $\Rightarrow c(f) \ge H(p_1, \ldots, p_m)$
		\item $\exists$ однозначный код $f: c(f) < H(p_1, \ldots, p_m) + 1$
	\end{itemize}
\end{theorem}
\begin{proof}
	В~одну сторону воспользуемся леммой Крафта-Макмилана и~неравенством Гиббса:
	$c(f) = \sum p_i n_i = -\sum p_i \log 2^{-n_i} \ge -\sum p_i \log p_i = H(p_1,
	\ldots, p_m)$.

	В~другую сторону, положим $n_i = \lceil \log \frac{1}{p_i} \rceil$, тогда
	по лемме Крафта-Макмилана существует код $f$~с~такими длинами. Тогда $c(f) =
	\sum p_i n_i = \sum p_i \lceil \log \frac{1}{p_i} \rceil < \sum p_i (\log
	\frac{1}{p_i} + 1) = H(p_1, \ldots, p_m) + 1$.
\end{proof}

\begin{proof}[Доказательство (леммы Крафта-Макмилана)]
	Построим по данным длинам код. Пусть $n_1 \ge \ldots \ge n_m$. Отложим отрезки
	длин $2^{-n_i}$ на отрезке $[0; 1]$ (это возможно по условию на сумму длин).
	Тогда $[\sum\limits_{i=1}^k 2^{-n_i}; \sum\limits_{i=1}^{k+1}]$~--- двоичный
	отрезок, то есть имеет вид $[\frac{l}{2^i}; \frac{l+1}{2^i}]$. Зная это,
	предъявим код следующим образом: будем спускаться по обычному бинарному
	отрезка, осуществляющему дихотомию отрезка $[0; 1]$ и~в~тот момент, когда мы
	приходим в~двоичный отрезок, завершаемся, выдавая соответствующий символ.
	Таким образом мы построили однозначный (более того, префиксный) код.

	В~обратную сторону, рассмотрим
	$$(\sum\limits_{i=1}^m 2^{-n_i})^k =
	\sum\limits_{w \in \Sigma^\ast} 2^{-|f(w)|} = \sum\limits_{l} \sum\limits_{w:
	|f(w)| = l} 2^{-l}.$$
	Заметим, что в~силу различности кодов длины $l$, внутренняя сумма не больше
	$1$, а~также, что $l \le k \cdot d, d = \max\limits_{i=1 \ldots m} n_i$, тогда
	получим что, исходное выражение не больше $dk$. Тогда для, если $\sum 2^{-n_i}
	> 1$, то для достаточно большого $k$ получим противоречие с~неравенством.
\end{proof}

\section{Оптимальный код}

Хотим решить задачу минимизации $\sum p_i n_i \rightarrow \min$ при условии
$\sum 2^{-n_i} \le 1$. Договоримся сразу $p_1 \ge \ldots \ge p_m, n_1 \le \ldots
\le n_m$.

\begin{claim}
	Пусть $f$~--- оптимальный код, тогда, с~очевидностью, $n_{m-1} = n_m$.
\end{claim}

Тогда перейдём к~задаче $\sum\limits_{i=1}^{m-1} p_i' {n_i} \rightarrow \min$
с~условием $\sum\limits_{i=1}^{m-1} 2^{-n_i} \le 1$, где $p_i'$~--- исправленные
вероятности. Пусть $\hat{n_i}$~--- оптимальное решение второй задачи, тогда
понятно, что по ним можно восстановить решение исходной: $n_i = \hat{n_i}$ для
$i \le m - 2, n_{m-1} = n_m = \hat{n_{m-1}} + 1$.

Таким образом, мы получили оптимальный код (это, очевидно, код Хаффмана).

Рассмотрим теперь следующую задачу: дана дискретная случайная величина $X \sim
(p_1, \ldots, p_m)$ и~честная монетка: $Z_1, \ldots \sim
Bern\left(\frac{1}{2}\right)$. Нужно придумать алгоритм, который по $Z_1,
\ldots$ моделирует величину $X$. Его естественно представлять деревом (возможно,
бесконечным).

Если $Y$~--- некоторая случайная величина, уже заданная таким деревом, притом
значения во всех листьях различны, тогда ясно, что ожидаемая глубина его
$ET = \sum\limits_{y} d(y) P(Y = y) = \sum\limits_{y} d(y) 2^{-d(y)} = H(Y)$.

\begin{claim}
	Пусть $p_i$~--- двоично-рациональные. $p_i = \sum\limits_j 2^{-n_{ij}}$. Тогда
	$H(X) \le ET < H(X) + 2$.
\end{claim}
\begin{proof}
	Оценка снизу явствует из того, что у~построенного дерева в~некоторых листах
	значения одинаковы, при замене их на разные, энтропия не уменьшится.
\end{proof}

Тоже самое можно сказать и~про не двоично-рациональные вероятности.

\end{document}
